# Execute below commands after opening PySpark Shell 
# Execute each command one by one

from pyspark.sql.types import StructType,StructField, StringType, IntegerType

person_list = [("Berry","","Allen",1,"M"),
        ("Oliver","Queen","",2,"M"),
        ("Robert","","Williams",3,"M"),
        ("Tony","","Stark",4,"F"),
        ("Rajiv","Mary","Kumar",5,"F")
]

schema = StructType([ \
        StructField("firstname",StringType(),True), \
        StructField("middlename",StringType(),True), \
        StructField("lastname",StringType(),True), \
        StructField("id", IntegerType(), True), \
        StructField("gender", StringType(), True), \    
 ])
 
 df = spark.createDataFrame(data=person_list,schema=schema)
 
 df.show(truncate=False)
 
 df.printSchema()

################Reading CSV file from hdfs path#####################
df1=spark.read.option("header",True).csv("/input_data/department.csv")
>>> df1=spark.read.option("header", True).csv("/input_data/departments.csv")
>>> df1.printSchema()
root
 |-- DEPARTMENT_ID: string (nullable = true)
 |-- DEPARTMENT_NAME: string (nullable = true)
 |-- MANAGER_ID: string (nullable = true)
 |-- LOCATION_ID: string (nullable = true)
#######if the spark environment at different place
df1=spark.read.option("header",True).csv("hdfs://namenode:8080/input_data/department.csv")


df2=spark.read.option("header",True).option("inferSchema",True).csv("/input_data/department.csv")
>>> df2=spark.read.option("header", True).option("inferSchema",True).csv("/input_data/departments.csv")>>> df1.printSchema()
root
 |-- DEPARTMENT_ID: integer (nullable = true)
 |-- DEPARTMENT_NAME: string (nullable = true)
 |-- MANAGER_ID: string (nullable = true)
 |-- LOCATION_ID: integer (nullable = true)


 
